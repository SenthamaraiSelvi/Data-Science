# -*- coding: utf-8 -*-
"""ML_Intern_Day4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PMoD1d-Gnr5GlFIWaz6dq6KrHReMtuaM
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""###Data Extraction"""

walmart=pd.read_csv("/content/sample_data/Walmart_Sales.csv")
df=pd.DataFrame(walmart)
df.head()

df.info()

df.describe()

df.isnull().sum()

"""###Data Transformation
           **Done for uniform units in the data
"""

df['Date'] = pd.to_datetime(df['Date'],errors='coerce')

df.columns

"""###Normal Distribution CHECK"""

from scipy.stats import norm
sns.distplot(df['Weekly_Sales'], fit = norm, color = 'deepskyblue')

# Is 'Weekly_Sales' (Label) is having outliers ?
sns.boxplot(df['Weekly_Sales'], orient = 'h')

"""###Outliers Detection and Removal
* Standardization(z-score): Use when the data follows a Gaussian (normal) distribution.
* It's useful for algorithms that assume normally distributed data (e.g., linear models, logistic regression).
* Normalization(Min-Max Scaling): Use when you know the data does not follow a Gaussian distribution.
* you want to bound the values within a specific range, which can be beneficial for algorithms that require bounded inputs (e.g., neural networks).
"""

numeric_data=df.drop(columns=['Date'])
# Find the outliers using z-score
from scipy.stats import zscore
z = np.abs(zscore(numeric_data))

print(np.where(z > 3.5))

df1 = numeric_data.drop(np.where((z > 3.5))[0])

sns.distplot(df1['Weekly_Sales'], fit = norm, color = 'deepskyblue')

"""###Feature Engineering & Feature Selection"""

df1.corr()

plt.figure(figsize = (10,8))
# annot = showing values on heatmap plot, cmap = color gradient
sns.heatmap(df1.corr(), annot = True, cmap = 'RdYlGn')

plt.figure(figsize = (8,8))
# annot = showing values on heatmap plot, cmap = color gradient
sns.heatmap(df1.corr()[['Weekly_Sales']], annot = True, cmap = 'RdYlGn')

"""###Cross Validation
  * It is process of splitting train & test samples randomnly to avoid overfitting of model.
"""

df1.columns

X = df1
Y = df1['Weekly_Sales']

# Split into train & test data
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)

"""###Linear Regression

"""

from sklearn.linear_model import LinearRegression
lr_model = LinearRegression()

lr_model.fit(x_train, y_train)

# r-squared
lr_model.score(x_test, y_test)

"""###Performance of LR Model"""

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

predictions = lr_model.predict(x_test)

# MSE
mean_squared_error(y_test, predictions)

# RMSE
np.sqrt(mean_squared_error(y_test, predictions))

mean_absolute_error(y_test, predictions)

y_test.min()

# r2_square
r2_score(y_test, predictions)

# Make predictions
y_pred_train = lr_model.predict(x_train)
y_pred_test = lr_model.predict(x_test)

# Combine training and testing data for visualization
y_train_pred_combined = np.concatenate((y_train, y_pred_train), axis=0)
y_test_pred_combined = np.concatenate((y_test, y_pred_test), axis=0)
actual_combined = np.concatenate((y_train, y_test), axis=0)
predicted_combined = np.concatenate((y_pred_train, y_pred_test), axis=0)

# Scatter Plot of Actual vs. Predicted Values
plt.figure(figsize=(10, 5))
plt.scatter(actual_combined, predicted_combined, color='blue', label='Predicted')
plt.plot([min(actual_combined), max(actual_combined)], [min(actual_combined), max(actual_combined)], color='red', linestyle='--', label='Ideal')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Actual vs Predicted Values')
plt.legend()
plt.show()

# Residual Plot
residuals = actual_combined - predicted_combined
plt.figure(figsize=(10, 5))
sns.residplot(x=predicted_combined, y=residuals, lowess=True, color='blue')
plt.axhline(0, color='red', linestyle='--')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.title('Residual Plot')
plt.show()